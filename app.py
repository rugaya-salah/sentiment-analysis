import streamlit as st
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import pandas as pd

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="ğŸ§  Tweet Sentiment Analyzer", layout="wide")
st.title("ğŸ§  Tweet Sentiment Analyzer")
st.write("Ø­Ù„Ù„ Ù…Ø´Ø§Ø¹Ø± Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
@st.cache_resource
def load_model():
    model_name = "cardiffnlp/twitter-roberta-base-sentiment"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSequenceClassification.from_pretrained(model_name)
    return pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)

sentiment_analyzer = load_model()

# Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù†Øµ
tweet_text = st.text_area("âœï¸ Ø§ÙƒØªØ¨ Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ù‡Ù†Ø§", height=100)

if st.button("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"):
    if tweet_text.strip():
        result = sentiment_analyzer(tweet_text)
        label = result[0]['label']
        score = round(result[0]['score'], 3)

        st.success(f"ğŸ“Œ Ø§Ù„Ù†ØªÙŠØ¬Ø©: **{label}** (Ø§Ù„Ø«Ù‚Ø©: {score})")
    else:
        st.warning("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ù†Øµ Ù‚Ø¨Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„")

# Ø±ÙØ¹ Ù…Ù„Ù CSV
uploaded_file = st.file_uploader("ğŸ“‚ Ø£Ùˆ Ø§Ø±ÙØ¹ Ù…Ù„Ù CSV ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ 'text'", type=['csv'])

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    if 'text' in df.columns:
        st.write("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª ÙÙŠ Ø§Ù„Ù…Ù„Ù...")
        df['sentiment'] = df['text'].apply(lambda x: sentiment_analyzer(str(x))[0]['label'])
        st.dataframe(df)
        csv_output = df.to_csv(index=False).encode('utf-8')
        st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ CSV", data=csv_output, file_name="tweet_sentiment_results.csv", mime="text/csv")
    else:
        st.error("âŒ Ø§Ù„Ù…Ù„Ù ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ Ø§Ø³Ù…Ù‡ 'text'")
